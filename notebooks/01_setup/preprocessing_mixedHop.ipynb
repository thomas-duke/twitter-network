{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import pickle\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROWS = 20000\n",
    "following = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/train.txt', 'r') as f:\n",
    "#     for i in range(NUM_ROWS): \n",
    "#         if f:\n",
    "#             line = next(f)\n",
    "#             nodes = line.split('\\t')\n",
    "#             source = int(nodes[0])\n",
    "#             sinks = list(map(int, nodes[1:]))\n",
    "            \n",
    "#             # disregard those followed by too many people\n",
    "#             if len(sinks) < 2500:\n",
    "#                 following[source] = sinks \n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUM_ROWS = 20000\n",
    "# following = defaultdict(list)\n",
    "\n",
    "# with open('data/train.txt', 'r') as f:\n",
    "#     for i in range(NUM_ROWS): \n",
    "#         if f:\n",
    "#             line = next(f)\n",
    "#             nodes = line.split('\\t')\n",
    "#             source = int(nodes[0])\n",
    "#             sinks = list(map(int, nodes[1:]))\n",
    "          \n",
    "#             following[source] = sinks \n",
    "#     f.close()\n",
    "\n",
    "# from itertools import product\n",
    "\n",
    "# full_graph = nx.DiGraph()\n",
    "# nodes = list(following.keys())\n",
    "\n",
    "# for n in nodes:\n",
    "#     targets = following[n]\n",
    "#     combinations = list(product([n], targets))\n",
    "#     full_graph.add_edges_from(combinations)\n",
    "    \n",
    "# nx.write_edgelist(full_graph, 'full_edgelist', data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import product\n",
    "\n",
    "# full_graph = nx.DiGraph()\n",
    "# nodes = list(following.keys())\n",
    "\n",
    "# for n in nodes:\n",
    "#     targets = following[n]\n",
    "#     combinations = list(product([n], targets))\n",
    "#     full_graph.add_edges_from(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph = nx.read_edgelist('filtered_edgelist', create_using=nx.DiGraph, nodetype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "test_pairs = {}\n",
    "with open('data/test-public.txt', 'r') as f:\n",
    "    test = csv.DictReader(f, delimiter='\\t')\n",
    "    for row in test:\n",
    "        source = row['Source']\n",
    "        sink = row['Sink']\n",
    "        test_pairs[source] = sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 1364537\n",
      "Number of edges: 5999507\n",
      "Average in degree:   4.3967\n",
      "Average out degree:   4.3967\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(train_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.write_edgelist(full_graph, 'filtered_edgelist', data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "NUM_SAMPLE = 300000\n",
    "\n",
    "# sample NUM_SAMPLE edges\n",
    "# true_edges = sample(train_graph.edges, NUM_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_nodes = list(test_pairs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 5306.93it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# NEW WAY OF SAMPLING\n",
    "# Sample on average 150 edges per source node\n",
    "PER_SOURCE = 150\n",
    "\n",
    "true_edges = []\n",
    "carry_over = 0\n",
    "for s in tqdm(source_nodes):\n",
    "    candidates = list(train_graph.edges([int(s)]))\n",
    "    num_need = PER_SOURCE + carry_over\n",
    "    if len(candidates) >= num_need:\n",
    "        true_edges.extend(sample(candidates, num_need))\n",
    "        carry_over = 0\n",
    "    else:\n",
    "        true_edges.extend(candidates)\n",
    "        carry_over = num_need - len(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_edges = []\n",
    "count_edge = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "while count_edge < NUM_SAMPLE:\n",
    "    # get a random node to start\n",
    "    source = int(choice(source_nodes))\n",
    "    # find missing edges from 2 distance\n",
    "    one_neighbors = list(train_graph.neighbors(source))\n",
    "    count_n1 = 0\n",
    "    for n1 in one_neighbors:\n",
    "        # get up to 150 missing edges from source\n",
    "        if count_n1 > 150:\n",
    "            count_edge += count_n1\n",
    "            break\n",
    "        else:\n",
    "            count_n2 = 0\n",
    "            two_neighbors = list(train_graph.neighbors(n1))\n",
    "        # get up to 15 missing edges from two neighbors\n",
    "        for n2 in two_neighbors:\n",
    "            if count_n2 > 15:\n",
    "                count_n1 += count_n2\n",
    "                break\n",
    "            else:\n",
    "                count_n3 = 0\n",
    "                # check three neighbors\n",
    "                three_neighbors = list(train_graph.neighbors(n2))\n",
    "                \n",
    "                # get up to 5 missing edges from three neighbors\n",
    "                for n3 in three_neighbors:\n",
    "                    if count_n3 > 5:\n",
    "                        count_n2 += count_n3\n",
    "                        break\n",
    "                    else:\n",
    "                        if not train_graph.has_edge(source, n3):\n",
    "                            count_n3 += 1\n",
    "                            false_edges.append((source, n3))\n",
    "                \n",
    "                # done with three neighbors, go back to current n2\n",
    "                if not train_graph.has_edge(source, n2):\n",
    "                    count_n2 += 1\n",
    "                    false_edges.append((source, n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(pair, graph):\n",
    "    u, v = pair[0], pair[1]\n",
    "    return (int(graph.has_edge(u, v)))\n",
    "\n",
    "def concatenate(node_set, label):\n",
    "    dataset = pd.DataFrame({'nodes': node_set, 'label': label})\n",
    "    return dataset\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label creation\n",
    "y_1 = list(map(partial(assign_label, graph=train_graph), true_edges))\n",
    "y_0 = list(map(partial(assign_label, graph=train_graph), false_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append y_true to y_train & true_edges to train_small\n",
    "y_train = y_1 + y_0\n",
    "edges_train = true_edges + false_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = concatenate(edges_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"600k_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

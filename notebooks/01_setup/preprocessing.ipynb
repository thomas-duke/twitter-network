{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import pickle\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROWS = 20000\n",
    "following = defaultdict(list)\n",
    "followed = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train.txt', 'r') as f:\n",
    "    for i in range(NUM_ROWS): \n",
    "        if f:\n",
    "            line = next(f)\n",
    "            nodes = line.split('\\t')\n",
    "            source = int(nodes[0])\n",
    "            sinks = list(map(int, nodes[1:]))\n",
    "            \n",
    "            # disregard those followed by too many people\n",
    "            if len(sinks) < 2500:\n",
    "                following[source] = sinks \n",
    "\n",
    "                # aggregate followers of users\n",
    "                for n in sinks:\n",
    "                    followed[n].append(source)\n",
    "                \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_popular = 0\n",
    "to_remove = []\n",
    "for key, value in followed.items():\n",
    "    if len(value) > 1:\n",
    "        count_popular += 1\n",
    "    else:\n",
    "        to_remove.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "587704"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776833"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "full_graph = nx.DiGraph()\n",
    "nodes = list(following.keys())\n",
    "\n",
    "for n in nodes:\n",
    "    targets = following[n]\n",
    "    combinations = list(product([n], targets))\n",
    "    full_graph.add_edges_from(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 1364537\n",
      "Number of edges: 5999507\n",
      "Average in degree:   4.3967\n",
      "Average out degree:   4.3967\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(full_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_edgelist(full_graph, 'filtered_edgelist', data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "NUM_SAMPLE = 50000\n",
    "\n",
    "# sample 50000 edges\n",
    "true_edges = sample(full_graph.edges, NUM_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_edges = []\n",
    "count_edge = 0\n",
    "all_nodes = list(full_graph.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "while count_edge < NUM_SAMPLE:\n",
    "    # get a random node to start\n",
    "    source = choice(nodes)\n",
    "    # find missing edges from 2 distance\n",
    "    one_neighbors = list(full_graph.neighbors(source))\n",
    "    count_n1 = 0\n",
    "    for n1 in one_neighbors:\n",
    "        if count_n1 > 100:\n",
    "            count_edge += count_n1\n",
    "            break\n",
    "        else:\n",
    "            count_n2 = 0\n",
    "            two_neighbors = list(full_graph.neighbors(n1))\n",
    "        # get up to 100 missing edges from source\n",
    "        for n2 in two_neighbors:\n",
    "            if count_n2 > 10:\n",
    "                count_n1 += count_n2\n",
    "                break\n",
    "            if not full_graph.has_edge(source, n2):\n",
    "                count_n2 += 1\n",
    "                false_edges.append((source, n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(pair, graph):\n",
    "    u, v = pair[0], pair[1]\n",
    "    return (int(graph.has_edge(u, v)))\n",
    "\n",
    "def concatenate(node_set, label):\n",
    "    dataset = pd.DataFrame({'nodes': node_set, 'label': label})\n",
    "    return dataset\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label creation\n",
    "y_1 = list(map(partial(assign_label, graph=full_graph), true_edges))\n",
    "y_0 = list(map(partial(assign_label, graph=full_graph), false_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append y_true to y_train & true_edges to train_small\n",
    "y_train = y_1 + y_0\n",
    "edges_train = true_edges + false_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = concatenate(edges_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"small_train.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
